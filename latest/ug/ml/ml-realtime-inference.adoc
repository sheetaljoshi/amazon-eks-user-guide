include::../attributes.txt[]

[.topic]
[#ml-realtime-inference]
= Running real-time online inference workloads on Amazon EKS
:info_titleabbrev: Real-time inference

[abstract]
--
Learn how to set up and manage real-time online inference workloads on Amazon EKS.
--

[TIP]
====
https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=4a9b4147-2490-4c63-bc9f-f8a84b122c8c&sc_channel=el[Register] for upcoming Amazon EKS AI/ML workshops.
====

This section is designed to help you deploy and operate real-time online inference workloads on Amazon Elastic Kubernetes Service (EKS). You'll find guidance on building optimized clusters with GPU-accelerated nodes, integrating {aws} services for storage and autoscaling, deploying sample models for validation, and key architectural considerations such as decoupling CPU and GPU tasks, selecting appropriate AMIs and instance types, and ensuring low-latency exposure of inference endpoints.

[.topiclist]
[[Topic List]]

include::ml-realtime-inference-cluster.adoc[leveloffset=+1]

include::ml-realtime-inference-llm-inference-vllm.adoc[leveloffset=+1]
